{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neoaman/diagnoflow/blob/main/notebooks/01_create_vector_store_FAISS_med.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSk53c56RduE"
      },
      "source": [
        "# Setup Ollama server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfhIO5CeOH4v",
        "outputId": "6e83d0f4-ee7b-4c8a-e591-582d0d2a4119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\n",
            "100  8575    0  8575    0     0  15871      0 --:--:-- --:--:-- --:--:-- 15879\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA GPU. Install lspci or lshw to automatically detect and install NVIDIA CUDA drivers.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "env: OLLAMA_HOST=0.0.0.0\n"
          ]
        }
      ],
      "source": [
        "# Download ollama\n",
        "! curl https://ollama.ai/install.sh | sh\n",
        "# Serve ollama\n",
        "%env OLLAMA_HOST=0.0.0.0\n",
        "!ollama serve &> /dev/null &\n",
        "!ollama pull gemma:2b &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TT9Hv9VOTW9",
        "outputId": "a1ba25fd-2e9c-4a4d-b4f5-0be29e45b609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%%writefile requirements.txt\n",
        "faiss-gpu\n",
        "langchain\n",
        "jq\n",
        "langchainhub\n",
        "icecream\n",
        "minio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyXWsmCIOZR6",
        "outputId": "10a63536-7bac-4cc1-9fc0-e1c81e902319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Download required python package\n",
        "! pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-o6Ee5aR3DY"
      },
      "source": [
        "# Test Ollama server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "BECw2Zm4Oh18",
        "outputId": "5bd708b4-19a0-4c1c-b137-8734f7164463"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "ic| llm(\"What is molecular formula of zinc di oxide ?\"): ('Sure, the molecular formula for zinc di oxide is ZnO2. It is a chemical '\n",
            "                                                          'compound composed of zinc and oxygen.')\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sure, the molecular formula for zinc di oxide is ZnO2. It is a chemical compound composed of zinc and oxygen.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.llms import Ollama\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from icecream import ic\n",
        "llm = Ollama(model=\"gemma:2b\",base_url=\"http://0.0.0.0:11434\",callback_manager = CallbackManager([StreamingStdOutCallbackHandler]))\n",
        "ic(llm(\"What is molecular formula of zinc di oxide ?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StHxnKB9SDLR"
      },
      "source": [
        "# Download data for vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VWSPG5aOyCR",
        "outputId": "c7d6f578-3b58-4d8c-e9e4-c78ddffc2f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-14 14:16:25--  https://github.com/project-baize/baize-chatbot/raw/main/data/medical_chat_data.json\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/project-baize/baize-chatbot/main/data/medical_chat_data.json [following]\n",
            "--2024-03-14 14:16:25--  https://raw.githubusercontent.com/project-baize/baize-chatbot/main/data/medical_chat_data.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 61608619 (59M) [text/plain]\n",
            "Saving to: ‘medical_chat_data.json’\n",
            "\n",
            "medical_chat_data.j 100%[===================>]  58.75M   291MB/s    in 0.2s    \n",
            "\n",
            "2024-03-14 14:16:26 (291 MB/s) - ‘medical_chat_data.json’ saved [61608619/61608619]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://github.com/project-baize/baize-chatbot/raw/main/data/medical_chat_data.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ0v5Y1sSm6e"
      },
      "source": [
        "# Store data in vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GodH2-AQPr_z"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import JSONLoader\n",
        "import json\n",
        "from pathlib import Path\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from minio import Minio\n",
        "\n",
        "file_path='/content/medical_chat_data.json'\n",
        "data = json.loads(Path(file_path).read_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U6vvyZW4AMa"
      },
      "outputs": [],
      "source": [
        "ACCESS_KEY = input(\"Enter access key:\")\n",
        "SECRET_KEY = input(\"Enter secret key:\")\n",
        "MINIO_CLIENT = Minio(\"s3.mlhub.in\", access_key=ACCESS_KEY, secret_key=SECRET_KEY, secure=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u6dqtXoPYIZ"
      },
      "outputs": [],
      "source": [
        "loader = JSONLoader(\n",
        "    file_path='/content/medical_chat_data.json',\n",
        "    jq_schema='.[]',\n",
        "    text_content=False,\n",
        "    json_lines=True\n",
        ")\n",
        "\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ji8NAcUPajx",
        "outputId": "6176b282-1ab6-4e54-dfbb-55c33f4ca9b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| len(data): 46867\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "46867"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ic(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvH1dbFxPdfh"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpGxqLGKS9uC",
        "outputId": "bce9d3de-2c7c-47a0-df9c-7b5299a15c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: OLLAMA_HOST=0.0.0.0\n"
          ]
        }
      ],
      "source": [
        "%env OLLAMA_HOST=0.0.0.0\n",
        "!ollama serve &> /dev/null &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XU6o80Z1hnn"
      },
      "source": [
        "## Run below section to initate the vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBiXYvjQV_re"
      },
      "outputs": [],
      "source": [
        "# NOTE Run if require to remove the vector database\n",
        "# !rm -r medical_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cie1Gs8CPlFP"
      },
      "outputs": [],
      "source": [
        "# NOTE RUN ONCE to initiate the vector db\n",
        "\n",
        "# START = 0\n",
        "# db = FAISS.from_documents(documents[(START*100):(START+1)*100], OllamaEmbeddings(model=\"gemma:2b\",base_url=\"http://0.0.0.0:11434\"))\n",
        "# db.save_local(\"medical_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAgTgecYefYA"
      },
      "outputs": [],
      "source": [
        "# NOTE RUN ONCE to initiate the vector db info\n",
        "\n",
        "# with open(\"medical_index/meta_info.txt\",\"w\") as mt:\n",
        "#     mt.write(str(START))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w0iIhAn4L3r"
      },
      "outputs": [],
      "source": [
        "# NOTE For initial upload only (testing purpose)\n",
        "# MINIO_CLIENT.fput_object(\"public\", \"medical_index/index.faiss\",\"/content/medical_index/index.faiss\")\n",
        "# MINIO_CLIENT.fput_object(\"public\", \"medical_index/index.pkl\",\"/content/medical_index/index.pkl\")\n",
        "# MINIO_CLIENT.fput_object(\"public\", \"medical_index/meta_info.txt\",\"/content/medical_index/meta_info.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwNlUnGpdSfG"
      },
      "source": [
        "### Setup and store in bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q4xkkNVWNaw"
      },
      "outputs": [],
      "source": [
        "# START = 1\n",
        "# for i in range(START,round(len(data)/100)):\n",
        "#     db.add_documents(documents[i*100:(i+1)*100])\n",
        "#     db.save_local(\"medical_index\")\n",
        "#     with open(\"medical_index/meta_info.txt\",\"w\") as mt:\n",
        "#         mt.write(f\"i:{i} -> from {i*100} to {(i+1)*100}\")\n",
        "#     MINIO_CLIENT.fput_object(\"public\", \"medical_index/index.faiss\",\"/content/medical_index/index.faiss\")\n",
        "#     MINIO_CLIENT.fput_object(\"public\", \"medical_index/index.pkl\",\"/content/medical_index/index.pkl\")\n",
        "#     MINIO_CLIENT.fput_object(\"public\", \"medical_index/meta_info.txt\",\"/content/medical_index/meta_info.txt\")\n",
        "#     print(i*100,(i+1)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKBYSNLH2BNY"
      },
      "source": [
        "## Resume work Execute if you know the DB exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq-BhD_E2FAV",
        "outputId": "15d73860-9a1e-4696-c339-585f5105f934"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<minio.datatypes.Object at 0x7a49ea3a32e0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MINIO_CLIENT.fget_object(\"public\",object_name=\"medical_index/index.faiss\",file_path=\"medical_index/index.faiss\")\n",
        "MINIO_CLIENT.fget_object(\"public\",object_name=\"medical_index/index.pkl\",file_path=\"/content/medical_index/index.pkl\")\n",
        "MINIO_CLIENT.fget_object(\"public\",object_name=\"medical_index/meta_info.txt\",file_path=\"/content/medical_index/meta_info.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4WUojTj3ch6",
        "outputId": "f7cad3c0-b5ae-402b-a0d9-5ba10ce8da17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: OLLAMA_HOST=0.0.0.0\n"
          ]
        }
      ],
      "source": [
        "%env OLLAMA_HOST=0.0.0.0\n",
        "!ollama serve &> /dev/null &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0TprAjz3JcU"
      },
      "outputs": [],
      "source": [
        "db = FAISS.load_local(\"medical_index\",embeddings=OllamaEmbeddings(model=\"gemma:2b\",base_url=\"http://0.0.0.0:11434\"),allow_dangerous_deserialization=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn-s70XDP4Nm",
        "outputId": "f30713d2-e504-4856-cf78-9fac73804bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36300 36400\n",
            "36400 36500\n",
            "36500 36600\n",
            "36600 36700\n",
            "36700 36800\n",
            "36800 36900\n",
            "36900 37000\n",
            "37000 37100\n",
            "37100 37200\n",
            "37200 37300\n",
            "37300 37400\n",
            "37400 37500\n",
            "37500 37600\n",
            "37600 37700\n",
            "37700 37800\n",
            "37800 37900\n",
            "37900 38000\n",
            "38000 38100\n",
            "38100 38200\n",
            "38200 38300\n",
            "38300 38400\n",
            "38400 38500\n",
            "38500 38600\n",
            "38600 38700\n",
            "38700 38800\n",
            "38800 38900\n",
            "38900 39000\n",
            "39000 39100\n",
            "39100 39200\n",
            "39200 39300\n",
            "39300 39400\n",
            "39400 39500\n",
            "39500 39600\n",
            "39600 39700\n",
            "39700 39800\n",
            "39800 39900\n",
            "39900 40000\n",
            "40000 40100\n",
            "40100 40200\n",
            "40200 40300\n",
            "40300 40400\n",
            "40400 40500\n",
            "40500 40600\n",
            "40600 40700\n",
            "40700 40800\n",
            "40800 40900\n",
            "40900 41000\n",
            "41000 41100\n",
            "41100 41200\n",
            "41200 41300\n",
            "41300 41400\n",
            "41400 41500\n",
            "41500 41600\n",
            "41600 41700\n",
            "41700 41800\n",
            "41800 41900\n",
            "41900 42000\n",
            "42000 42100\n",
            "42100 42200\n",
            "42200 42300\n",
            "42300 42400\n",
            "42400 42500\n",
            "42500 42600\n",
            "42600 42700\n",
            "42700 42800\n",
            "42800 42900\n",
            "42900 43000\n",
            "43000 43100\n",
            "43100 43200\n",
            "43200 43300\n",
            "43300 43400\n",
            "43400 43500\n",
            "43500 43600\n",
            "43600 43700\n",
            "43700 43800\n",
            "43800 43900\n",
            "43900 44000\n",
            "44000 44100\n",
            "44100 44200\n",
            "44200 44300\n",
            "44300 44400\n",
            "44400 44500\n",
            "44500 44600\n",
            "44600 44700\n",
            "44700 44800\n",
            "44800 44900\n",
            "44900 45000\n",
            "45000 45100\n",
            "45100 45200\n",
            "45200 45300\n",
            "45300 45400\n",
            "45400 45500\n",
            "45500 45600\n",
            "45600 45700\n",
            "45700 45800\n",
            "45800 45900\n",
            "45900 46000\n",
            "46000 46100\n",
            "46100 46200\n",
            "46200 46300\n",
            "46300 46400\n",
            "46400 46500\n",
            "46500 46600\n",
            "46600 46700\n",
            "46700 46800\n",
            "46800 46900\n"
          ]
        }
      ],
      "source": [
        "START = 363\n",
        "for i in range(START,round(len(data)/100)):\n",
        "    db.add_documents(documents[i*100:(i+1)*100])\n",
        "    db.save_local(\"medical_index\")\n",
        "    with open(\"medical_index/meta_info.txt\",\"w\") as mt:\n",
        "        mt.write(f\"i:{i} -> from {i*100} to {(i+1)*100}\")\n",
        "    MINIO_CLIENT.fput_object(\"public\", \"medical_index/index.faiss\",\"/content/medical_index/index.faiss\")\n",
        "    MINIO_CLIENT.fput_object(\"public\", \"medical_index/index.pkl\",\"/content/medical_index/index.pkl\")\n",
        "    MINIO_CLIENT.fput_object(\"public\", \"medical_index/meta_info.txt\",\"/content/medical_index/meta_info.txt\")\n",
        "    print(i*100,(i+1)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ydM_1LYQGY_",
        "outputId": "eb7da7b3-6de8-4d5b-b811-952163e9a372"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46867"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
